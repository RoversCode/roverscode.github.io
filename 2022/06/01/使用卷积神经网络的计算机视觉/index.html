<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"roverscode.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="二维卷积层 在对图像得卷积中，内核的大小对应图片被卷积的区域，这一区域称为接受野。如果在图片的边缘，不够接受野的区域元素，补0。  步幅的概念和一维卷积是一样的。   卷积核 假设卷积核为7x7的矩阵，现在有两个卷积核。第一个卷积核除中间列的元素为1，其余全为0。第二个卷积核除中间行的元素为1，其余全为0。  如果层中的所有神经元都使用相同的垂直线滤波器（第一个卷积核）(和相同的偏置项)，并且向">
<meta property="og:type" content="article">
<meta property="og:title" content="使用卷积神经网络的计算机视觉">
<meta property="og:url" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/index.html">
<meta property="og:site_name" content="Junjie的博客|Rovers">
<meta property="og:description" content="二维卷积层 在对图像得卷积中，内核的大小对应图片被卷积的区域，这一区域称为接受野。如果在图片的边缘，不够接受野的区域元素，补0。  步幅的概念和一维卷积是一样的。   卷积核 假设卷积核为7x7的矩阵，现在有两个卷积核。第一个卷积核除中间列的元素为1，其余全为0。第二个卷积核除中间行的元素为1，其余全为0。  如果层中的所有神经元都使用相同的垂直线滤波器（第一个卷积核）(和相同的偏置项)，并且向">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled1.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled2.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled3.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled4.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled5.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled6.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled7.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled8.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled9.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled10.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled11.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled12.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled13.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled14.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled15.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled16.png">
<meta property="og:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled17.png">
<meta property="article:published_time" content="2022-06-01T10:15:38.000Z">
<meta property="article:modified_time" content="2022-07-02T05:08:33.013Z">
<meta property="article:author" content="Jack Liu">
<meta property="article:tag" content="NoteBook">
<meta property="article:tag" content="Computer Vision">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled.png">


<link rel="canonical" href="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/","path":"2022/06/01/使用卷积神经网络的计算机视觉/","title":"使用卷积神经网络的计算机视觉"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>使用卷积神经网络的计算机视觉 | Junjie的博客|Rovers</title>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?17864ebba3e6ef55a64f4c43f57c1018"></script>




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Junjie的博客|Rovers</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">1.</span> <span class="nav-text"> 二维卷积层</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="nav-number">1.1.</span> <span class="nav-text"> 卷积核</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A0%86%E5%8F%A0%E5%A4%9A%E4%B8%AA%E7%89%B9%E5%BE%81%E5%9B%BE"><span class="nav-number">1.2.</span> <span class="nav-text"> 堆叠多个特征图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensorflow%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.3.</span> <span class="nav-text"> Tensorflow的简单实现</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="nav-number">2.</span> <span class="nav-text"> 池化层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E6%96%B9%E5%90%91%E7%9A%84%E5%8D%B7%E7%A7%AF"><span class="nav-number">2.0.1.</span> <span class="nav-text"> 深度方向的卷积</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#cnn%E6%9E%B6%E6%9E%84"><span class="nav-number">3.</span> <span class="nav-text"> CNN架构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lenet-5"><span class="nav-number">4.</span> <span class="nav-text"> LeNET-5</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#alexnet"><span class="nav-number">5.</span> <span class="nav-text"> AlexNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#googlenet"><span class="nav-number">6.</span> <span class="nav-text"> GoogLeNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#vgcnet"><span class="nav-number">7.</span> <span class="nav-text"> VGCNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#resnet"><span class="nav-number">8.</span> <span class="nav-text"> ResNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#xception"><span class="nav-number">9.</span> <span class="nav-text"> Xception</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#senet"><span class="nav-number">10.</span> <span class="nav-text"> SENet</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jack Liu"
      src="/uploads/avatar.png">
  <p class="site-author-name" itemprop="name">Jack Liu</p>
  <div class="site-description" itemprop="description">To Be Algorithm Engineer</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button site-overview-item animated">
    <button><i class="fa fa-comment"></i>
      Chat
    </button>
  </div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/RoversCode" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;RoversCode" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/as949179700?spm=1000.2115.3001.5343" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;as949179700?spm&#x3D;1000.2115.3001.5343" rel="noopener" target="_blank"><i class="fab fa-c fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/27270848?spm_id_from=333.1007.0.0" title="BiliBili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;27270848?spm_id_from&#x3D;333.1007.0.0" rel="noopener" target="_blank"><i class="fab fa-bilibili fa-fw"></i>BiliBili</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/tian-qiao-di-xia-tao-mi-de-ren" title="ZhiHu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;tian-qiao-di-xia-tao-mi-de-ren" rel="noopener" target="_blank"><i class="fab fa-zhihu fa-fw"></i>ZhiHu</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Blogrolls
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.vstay.cn/" title="https:&#x2F;&#x2F;www.vstay.cn&#x2F;" rel="noopener" target="_blank">Vstay</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.zhihu.com/people/o-shui-ge-er" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;o-shui-ge-er" rel="noopener" target="_blank">水歌儿's ZhiHu</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://roverscode.github.io/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.png">
      <meta itemprop="name" content="Jack Liu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Junjie的博客|Rovers">
      <meta itemprop="description" content="To Be Algorithm Engineer">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="使用卷积神经网络的计算机视觉 | Junjie的博客|Rovers">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          使用卷积神经网络的计算机视觉
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-06-01 18:15:38" itemprop="dateCreated datePublished" datetime="2022-06-01T18:15:38+08:00">2022-06-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-07-02 13:08:33" itemprop="dateModified" datetime="2022-07-02T13:08:33+08:00">2022-07-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/Convolutional-Networks/" itemprop="url" rel="index"><span itemprop="name">Convolutional Networks</span></a>
        </span>
    </span>

  
    <span id="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" class="post-meta-item leancloud_visitors" data-flag-title="使用卷积神经网络的计算机视觉" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/06/01/使用卷积神经网络的计算机视觉/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>7.5k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>7 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="二维卷积层"><a class="markdownIt-Anchor" href="#二维卷积层"></a> 二维卷积层</h1>
<p>在对图像得卷积中，内核的大小对应图片被卷积的区域，这一区域称为<strong>接受野。如果在图片的边缘，不够接受野的区域元素，补0。</strong></p>
<ul>
<li>步幅的概念和一维卷积是一样的。</li>
</ul>
<h2 id="卷积核"><a class="markdownIt-Anchor" href="#卷积核"></a> 卷积核</h2>
<p>假设卷积核为7x7的矩阵，现在有两个卷积核。第一个卷积核除中间列的元素为1，其余全为0。第二个卷积核除中间行的元素为1，其余全为0。</p>
<ul>
<li>如果层中的所有神经元都使用相同的垂直线滤波器（第一个卷积核）(和相同的偏置项)，并且向网络输入底下的图片，那么会输出左上方的图像。
<ul>
<li>可以看到，垂直白线被加强，其余部分变得模糊。</li>
</ul>
</li>
<li>类似，用水平线滤波器(第二个卷积核)，水平的白线得到增强，而其余部分被模糊掉。</li>
</ul>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled.png" class="" title="this is example">
<p>所以，使用相同的滤波器的充满神经元的层会输出一个特征图，该图突出显示图像中<strong>最激活滤波器的区域。</strong></p>
<p>尽管这样说，但是我们在使用二维卷积网络的时候，并不需要自己手动定义滤波器；在训练过程中，卷积层将<strong>自动学习对其任务最有用的滤波器</strong>。</p>
<span id="more"></span>
<h2 id="堆叠多个特征图"><a class="markdownIt-Anchor" href="#堆叠多个特征图"></a> 堆叠多个特征图</h2>
<p>滤波器的数量是我们自己的定义的，<strong>每一个滤波器都会输出一个特征图</strong>。另外，之所以一直说CNN可以大大减少模型的参数，是因为每一个特征图中的神经元的计算，用的是一个滤波器。即共享参数。</p>
<ul>
<li>一般的彩色图像有三个通道：RGB,</li>
<li>灰色图像只有一个通道</li>
</ul>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled1.png" class="" title="this is example">
<h2 id="tensorflow的简单实现"><a class="markdownIt-Anchor" href="#tensorflow的简单实现"></a> Tensorflow的简单实现</h2>
<p>在Tensorflow中，输入图像的形状通常表示为<code>[height,width,channels]</code>。加上mini-batch，就是<code>[mini-batch,hegiht,width,channels]</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_sample_image</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load sample images</span></span><br><span class="line">china = load_sample_image(<span class="string">&quot;china.jpg&quot;</span>) / <span class="number">255</span></span><br><span class="line"></span><br><span class="line">flower = load_sample_image(<span class="string">&quot;flower.jpg&quot;</span>) / <span class="number">255</span></span><br><span class="line">images = np.array([china, flower])</span><br><span class="line"><span class="built_in">print</span>(images.shape)</span><br><span class="line">batch_size, height, width, channels = images.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create 2 filters</span></span><br><span class="line">filters = np.zeros(shape=(<span class="number">7</span>, <span class="number">7</span>, channels, <span class="number">2</span>), dtype=np.float32)</span><br><span class="line">filters[:, <span class="number">3</span>, :, <span class="number">0</span>] = <span class="number">1</span>  <span class="comment"># vertical line</span></span><br><span class="line">filters[<span class="number">3</span>, :, :, <span class="number">1</span>] = <span class="number">1</span>  <span class="comment"># horizontal line</span></span><br><span class="line"></span><br><span class="line">outputs = tf.nn.conv2d(images, filters, strides=<span class="number">1</span>, padding=<span class="string">&quot;SAME&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(outputs.shape)</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">32.0</span>, <span class="number">16.0</span>)  <span class="comment">#调整图片大小</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(outputs[<span class="number">0</span>, :, :, <span class="number">0</span>], cmap=<span class="string">&quot;gray&quot;</span>) <span class="comment"># plot 1st image&#x27;s 2nd feature map</span></span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>) <span class="comment"># Not shown in the book</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(outputs[<span class="number">0</span>, :, :, <span class="number">1</span>], cmap=<span class="string">&quot;gray&quot;</span>) <span class="comment"># plot 1st image&#x27;s 2nd feature map</span></span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>) <span class="comment"># Not shown in the book</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">plt.imshow(china) <span class="comment"># plot 1st image&#x27;s 2nd feature map</span></span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>) <span class="comment"># Not shown in the book</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled2.png" class="" title="this is example">
<h1 id="池化层"><a class="markdownIt-Anchor" href="#池化层"></a> 池化层</h1>
<aside> 💡 池化层通常独立地作用于每个输入通道，因此输出深度与输入深度相同
</aside>
<p>这一层跟计算跟NLP似乎没什么不一样。但是，对于图像来说，池化有着不一样的，可以用来总结的特性。</p>
<ul>
<li>
<p>最大池化层为小变换引入了一定程度的不变性。</p>
<ul>
<li>有这样的一种情况，两张照片里面的事物是一样的，但是在照片里面的位置不一致。这种情况下，有可能利用最大池化，得到的特征图，是一致的。</li>
</ul>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled3.png" class="" title="this is example">
<ul>
<li>但是这种不变性，并不是一直需要的。比如语义分割（根据像素所属的对象，对图像中的每个像素进行分类的任务)；显示，如果输入图像向右平移一个像素，则输出也应向右平移一个像素。在这种情况下，<strong>我们的目标是等变性而不是不变性：输入的微小变化应导致输出的相应微小变化。</strong></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">max_pool = keras.layers.MaxPool2D(pool_size=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h3 id="深度方向的卷积"><a class="markdownIt-Anchor" href="#深度方向的卷积"></a> 深度方向的卷积</h3>
<p>在图像中，还有一个不常见的卷积方式，深度方向。在TensorFlow的底层深度学习API，有这个工具。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DepthMaxPool</span>(keras.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, pool_size, strides=<span class="literal">None</span>, padding=<span class="string">&quot;VALID&quot;</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        <span class="keyword">if</span> strides <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            strides = pool_size</span><br><span class="line">        self.pool_size = pool_size</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.padding = padding</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        <span class="keyword">return</span> tf.nn.max_pool(inputs,</span><br><span class="line">                              ksize=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, self.pool_size),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, self.pool_size),</span><br><span class="line">                              padding=self.padding)</span><br><span class="line"></span><br><span class="line">depth_pool = DepthMaxPool(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">&quot;/cpu:0&quot;</span>): <span class="comment"># there is no GPU-kernel yet</span></span><br><span class="line">    depth_output = depth_pool(cropped_images)</span><br><span class="line">depth_output.shape</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Input&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plot_color_image(cropped_images[<span class="number">0</span>])  <span class="comment"># plot the 1st image</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Output&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plot_image(depth_output[<span class="number">0</span>, ..., <span class="number">0</span>])  <span class="comment"># plot the output for the 1st image</span></span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled4.png" class="" title="this is example">
<h1 id="cnn架构"><a class="markdownIt-Anchor" href="#cnn架构"></a> CNN架构</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"></span><br><span class="line">DefaultConv2D = partial(keras.layers.Conv2D,</span><br><span class="line">                        kernel_size=<span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&quot;SAME&quot;</span>)</span><br><span class="line"></span><br><span class="line">model = keras.models.Sequential([</span><br><span class="line">    DefaultConv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">7</span>, input_shape=[<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]),</span><br><span class="line">    keras.layers.MaxPooling2D(pool_size=<span class="number">2</span>),</span><br><span class="line">    DefaultConv2D(filters=<span class="number">128</span>),</span><br><span class="line">    DefaultConv2D(filters=<span class="number">128</span>),</span><br><span class="line">    keras.layers.MaxPooling2D(pool_size=<span class="number">2</span>),</span><br><span class="line">    DefaultConv2D(filters=<span class="number">256</span>),</span><br><span class="line">    DefaultConv2D(filters=<span class="number">256</span>),</span><br><span class="line">    keras.layers.MaxPooling2D(pool_size=<span class="number">2</span>),</span><br><span class="line">    keras.layers.Flatten(),</span><br><span class="line">    keras.layers.Dense(units=<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    keras.layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    keras.layers.Dense(units=<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    keras.layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    keras.layers.Dense(units=<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<ul>
<li>随着CNN向输出层延申，滤波器的数量会增加。这是有有意义的，因为低层特征的数量通常很少(例如小圆圈、水平线)，但是又很多不同的方法可以将他们组合成更高层次的特征。<strong>通常的做法是在每个池化层之后将滤波器的数量加倍。</strong></li>
<li>该CNN架构在 Fashion MNIST数据集上，精度达到90%以上。</li>
</ul>
<h1 id="lenet-5"><a class="markdownIt-Anchor" href="#lenet-5"></a> LeNET-5</h1>
<p>LeNET-5是1998年，Yann LeCun创建的。已被广泛用于手写数字识别(MNIST)。它由以下构成。</p>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled5.png" class="" title="this is example">
<p>这里有些细节要注意</p>
<ul>
<li>MNIST的图像时28<em>28的，但是将其零填充为32</em>32像素，在送入网络之前进行归一化。</li>
<li>C3特征图的大多数神经元仅链接到了在S2特征图中的三个或四个神经元（而不是S2特征的所有6个）。</li>
<li>输出层有点特殊：每个神经元输出的时输入向量和权重向量之间的<strong>欧几里得距离的平方</strong>，而不是计算输入向量和权重向量的矩阵乘法。</li>
</ul>
<h1 id="alexnet"><a class="markdownIt-Anchor" href="#alexnet"></a> AlexNet</h1>
<p>AlexNet架构，在2012中被提出。与LeNet5-相似，只是更大更深，它时第一个将卷积层直接堆叠在一起的方法，而不是将池化层堆叠在每个卷积层之上。下图是其架构。</p>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled6.png" class="" title="this is example">
<ul>
<li>
<p>为了减少过拟合，作者使用了两种正则化技术。在训练期间对F9和F10的输出使用了50%的Dropout。</p>
</li>
<li>
<p>他们通过随机变换训练图像的各种偏移量、水平翻转及更改亮度条件来执行数据增强。</p>
</li>
<li>
<p>AlexNet还在层C1和C3的ReLU之后立即使用了归一化步骤，称为局部响应归一化(LRN）：最强激活的神经元会抑制位于相邻特征图中相同位置的其他神经元。相关公式为：</p>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled7.png" class="" title="this is example">
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">b_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是位于特征图<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>中位于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">u</span></span></span></span>行和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span>行的神经元的归一化输出(仅考虑位于此行的列的神经元，因此未显示<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">u</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span>)。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">a_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是ReLU之后但未归一化之前该神经元的激活。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>是超参数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>是pian’zhi，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span></span></span></span>称深度半径。</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">f_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是特征图数量</li>
</ul>
</li>
<li>
<p>AlexNet中，超参数的设置如下：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">r=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.00002</mn></mrow><annotation encoding="application/x-tex">\alpha=0.00002</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord">2</span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">\beta=0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span><span class="mord">5</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>。</p>
</li>
</ul>
<h1 id="googlenet"><a class="markdownIt-Anchor" href="#googlenet"></a> GoogLeNet</h1>
<p>GoogLeNet由Google研究院的Christian Szegedy等人开发。赢下了2014年的ILSVRC(大规模视觉识别挑战)比赛。这种出色的性能在很大程度上是由于该网络比以前的CNN更深。</p>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled8.png" class="" title="this is example">
<ul>
<li>
<p>称为盗梦空间(inception)模块的子网能使用GoogLeNet比以前的架构更有效地私用参数。整个GoogLeNet实际上只有AlexNet<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><mn>10</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{10}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>的参。</p>
</li>
<li>
<p>下图是inception模块的架构</p>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled9.png" class="" title="this is example">
<ul>
<li>符号<strong>3X3+1 (S)</strong>，表示该层使用3x3内核，步幅为1且填充为”same”。</li>
<li>首先将输入信号复制并馈送到四个不同的层。</li>
<li>所有的卷积层都使用ReLU激活函数。</li>
</ul>
</li>
<li>
<p>inception模块，带有1x1内核的卷积层目的</p>
<ul>
<li>虽然它们无法识别空间特征，但它们可以识别<strong>沿深度维度的特征</strong>。</li>
<li>它们输出比输入更少的特征图，因此它们充当了瓶颈层，这意味着它们降低了维度。这减少了计算量和参数数量，加快了训练速度，提高了泛化能力。</li>
<li>每对卷积层[(1x1,3x3]和[1x1,5x5])就像一个强大的卷积层，能够识别更复杂的模式。实际上，这对卷积层不是在整个图像上扫描简单的线性分类器，而是在整个图像上扫描了两层神经网络。</li>
<li>所以整个inception模块视为类固醇上的卷积层，能够输出以各种比例尺寸识别的复杂模式的特征图。</li>
</ul>
</li>
<li>
<p>每个inception模块中的6个数字表示模块中每个卷积层输出的特殊图的数量。</p>
</li>
</ul>
<p>让我们看看这个网络：</p>
<ol>
<li>前两层将图像的高度和宽度除以4(因此将面积除以16)以减少计算机量。第一层使用较大的内核，因此可以保留很多信息。</li>
<li>局部响应归一化层(LRN)确保前面的层学习各种各样的特征</li>
<li>接下来两个卷积层，其中第一层就像之前说的瓶颈层。我们可以将这两个卷积层视为更智能的卷积层。</li>
<li>同样，LRN可确保先前的层识别各种模式。</li>
<li>最大池化层将图像的高度和宽度减少到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，再次加快了计算速度。</li>
<li>然后时9个inception模块的高堆叠，与几个最大池化层交错以减少维度并加快网络速度。</li>
<li>接下来，全局平均池化层树池每个特征图的均值：<strong>这将丢弃所有剩余的空间信息</strong>，这是可以的，因为在该点上没有太多的空间信息。</li>
<li>最后一层时不言而喻的：为了进行正则化而dropout，然后是一个具有1000个单元的全连接层(因为有1000个类)和一个softmax激活函数来输出估计的类别概率。</li>
</ol>
<blockquote>
<p>原始的GoogleNet架构还包括两个辅助分类器，它们插入在第3和第6个inception模块的顶部。都由一个平均池化层，一个卷积层，两个全连接层和一个softmax激活层组成。在训练期间，它们的30%损失被添加到总损失中，目的是解决梯度消失问题并正则化网络。但是后面证明，这两个辅助分类器并没有什么用。</p>
</blockquote>
<h1 id="vgcnet"><a class="markdownIt-Anchor" href="#vgcnet"></a> VGCNet</h1>
<p>2014年的ILSVRC的亚军是VGCNet。它具有非常简单和经典的架构，具有2或3个卷积层和一个池化层，然后又有2或3个卷积层和一个池化层，依次类推，最终会有两个MLP和输出层。它仅使用3x3滤波器，但是使用了很多。</p>
<h1 id="resnet"><a class="markdownIt-Anchor" href="#resnet"></a> ResNet</h1>
<p>何凯明等使用残差网络(ResNet)赢得了ILSVRC 2015挑战赛。获胜的变体使用了由152层组成的非常深的CNN（其他的变体有34，50和101层）。</p>
<blockquote>
<p>它证实了一个趋势：模型变得越来越深，参数越来越少。</p>
</blockquote>
<ul>
<li>能够训练这种深层网络的关键是使用跳过链接（快捷链接）：馈入层的信号也将添加到位于堆栈上方的层的输出中。</li>
</ul>
<p><strong>残差学习</strong></p>
<p>在训练神经网络时，目标是使其称为目标函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>的模型。如果将输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>添加到网络的输出(如下图），则网络将被迫建模<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>−</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">f(x)=h(x)-x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>而不是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">h</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>。这称为残差学习。</p>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled10.png" class="" title="this is example">
<ul>
<li>初始化常规神经网络时，其权重接近零，因此网络仅输出接近零的值。如果添加跳过链接，则生成的网络仅输出其输入的副本。也就是说，它首相对恒等函数建模。</li>
<li>此外，如果添加许多跳过连接，即使几层还没有开始学习，网络也可以开始取得进展。借助跳过连接，信号可以轻松地在整个网络中传播。**深度残差网络可以看作是残差单元(RU)地堆栈。**其中每个残差单元都是具有跳过连接地小型神经网络。</li>
</ul>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled11.png" class="" title="this is example">
<p>现在可以看一下ResNet的架构了，如下图。</p>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled12.png" class="" title="this is example">
<ul>
<li>
<p>它非常简单。它的开始和结束与GoogleNet完全相同(除了没有Dropout)，在两者之间只是一堆非常简单的残差单元。</p>
</li>
<li>
<p>每个残差单元由两个卷积层（没有池化层）组成，具有批量归一化(BN)和ReLU激活，使用3x3内核并保留空间维度(步幅1，”same”填充)</p>
</li>
<li>
<p>这里有一个注意点，特征图的数量每隔几个残差单元就增加一倍，同时高度和宽度也减半(使用<strong>步幅为2</strong>的卷积层)。</p>
<ul>
<li>在这种情况下，输入不能直接添加到残差单元的输出，因为它们的形状不同。为了解决这个问题，输入将通过步幅为2且具有正确数量的输出特征图的1x1卷积层</li>
</ul>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled13.png" class="" title="this is example">
</li>
</ul>
<h1 id="xception"><a class="markdownIt-Anchor" href="#xception"></a> Xception</h1>
<p>Xception在2016年提出，它在很大的视觉任务上(3.5亿张图像和17000个类别)明显优于Inception-v3。它用称为<strong>深度方向可分离卷积层(或简称为可分离卷积层)的特殊类型替代了inception模块。</strong></p>
<blockquote>
<p>实际上，可分离卷积层以前在某些CNN架构中使用过，但是它们并不像在Xception中那么重要</p>
</blockquote>
<ul>
<li>
<p>常规卷积层使用的滤波器试图同时识别空间模式(椭圆形)和跨通道模式(例如，嘴+鼻子+眼睛=脸)，但可分离的卷积层的强烈假设是<strong>空间模式和跨通道模式可以单独建模</strong>，如下图。</p>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled14.png" class="" title="this is example">
<ul>
<li>它由两部分组成：</li>
<li>第一部分为每个输入特征图应用一个空间滤波器</li>
<li>第二部分专门寻找跨通道模式——它是具有1X1滤波器的常规卷积层。</li>
</ul>
</li>
</ul>
<h1 id="senet"><a class="markdownIt-Anchor" href="#senet"></a> SENet</h1>
<p>ILSVRC 2017的冠军是Squeeze-and-Excitation Network(SENet)。这个架构扩展了现有架构(例如inception网络和ResNets)，并提高了它们的性能。</p>
<blockquote>
<p>inception和ResNet的扩展版本分别称为SE-Inception和SE-ResNet</p>
</blockquote>
<ul>
<li>SENet向原始架构中的每个单元(即每个inception模块或残差单元)<strong>添加了一个称为SE块的小型神经网络</strong>，如下图</li>
</ul>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled15.png" class="" title="this is example">
<ul>
<li>SE块分析其连接的单元的输出，仅专注于深度维度(它不关心任何空间模式)，并了解哪一些特征通常是最活跃的。然后，它使用此信息重新校准特征图。如下图所示</li>
</ul>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled16.png" class="" title="this is example">
<ul>
<li>
<p>一个SE块可能会了解到嘴、鼻子和眼睛通常在图片中同时出现：如果看到嘴巴和鼻子还应该看到眼睛。因此，如果该块在嘴和鼻子特征图中看到强烈的激活，而在眼睛特征图中只有轻微的激活，则它将增强眼睛特征图。<strong>更一般来说，SE会降低无关的特征图。</strong></p>
</li>
<li>
<p>SE快仅由三层组成。如下图所示</p>
<ul>
<li>全局平均池化层</li>
<li>使用ReLU激活函数的MLP</li>
<li>使用sigmoid激活函数的MLP</li>
</ul>
<img src="/2022/06/01/%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/Untitled17.png" class="" title="this is example">
<ul>
<li>全局平均池化层为每个特征图计算平均激活：例如，如果其输入包含256个特征图，则它将暑促和256个数字，代表每个滤波器的总体响应。</li>
<li>下一个层是”挤压”发生的地方：此层的神经元要明显少于256个，**通常比特征图的数组少16倍。**这是特征响应分布的低维向量表示（即嵌入）。这个瓶颈步骤迫使SE块学习特征组合的一般表征形式。</li>
<li>最后，输出层进行嵌入，**并输出一个重新校准的向量，每个特征图包含一个0-1之间的数字。**然后将特征图与该重新校准的向量相乘，因此不相关的特征按比例缩小，而相关特征(重新校准分数接近1)则不予考虑。</li>
</ul>
</li>
</ul>

    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="reward-container">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作!</div>
  <button>
    Donate
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.png" alt="Jack Liu WeChat Pay">
        <span>WeChat Pay</span>
      </div>
      <div>
        <img src="/images/alipay.png" alt="Jack Liu Alipay">
        <span>Alipay</span>
      </div>

  </div>
</div>

          <div class="followme">
  <span>Welcome to my other publishing channels</span>

  <div class="social-list">

      <div class="social-item">
        <a target="_blank" class="social-link" href="https://github.com/RoversCode">
          <span class="icon">
            <i class="fab fa-github"></i>
          </span>

          <span class="label">GitHub</span>
        </a>
      </div>

      <div class="social-item">
        <a target="_blank" class="social-link" href="https://www.zhihu.com/people/tian-qiao-di-xia-tao-mi-de-ren">
          <span class="icon">
            <i class="fab fa-zhihu"></i>
          </span>

          <span class="label">Zhihu</span>
        </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/NoteBook/" rel="tag"><i class="fa fa-tag"></i> NoteBook</a>
              <a href="/tags/Computer-Vision/" rel="tag"><i class="fa fa-tag"></i> Computer Vision</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/05/31/%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%98%A0%E5%B0%84%E6%96%B9%E6%B3%95/" rel="prev" title="图像的两种映射方法">
                  <i class="fa fa-chevron-left"></i> 图像的两种映射方法
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/06/03/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%AE%9A%E4%BD%8D/" rel="next" title="分类与定位入门">
                  分类与定位入门 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jack Liu</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">150k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">2:16</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div><script defer src="/lib/three.js"></script><script defer src="/lib/lines.js"></script><script defer src="/lib/sphere.js"></script>

    </div>
  </footer>

  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>
<script class="next-config" data-name="chatra" type="application/json">{"enable":true,"async":true,"id":"RDWmpXgyaTrhDacBF"}</script>
<script src="/js/third-party/chat/chatra.js"></script>
<script async src="https://call.chatra.io/chatra.js"></script>





  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":"ture","app_id":"vaQ3aKMLINcogqAieKeyopEl-MdYXbMMI","app_key":"0g5c7cfFntvGevgfC1j9EFNy","server_url":"https://vaq3akml.api.lncldglobal.com","security":true}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css" integrity="sha256-TThEtR+XalhWKkfF383YLOrI50NGNeIqrzS+q08afrY=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/copy-tex.min.css" integrity="sha256-Wk20U9mS/kHGcSgkjSiRezW5exqT6wAOKwySOaLotXM=" crossorigin="anonymous">
  <script class="next-config" data-name="katex" type="application/json">{"copy_tex_js":{"url":"https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/copy-tex.min.js","integrity":"sha256-etSqbSVF4+Lwe8MGk/Vanc1sR+mWv+qOG73fxWw9p94="}}</script>
  <script src="/js/third-party/math/katex.js"></script>


<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"roverscode","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
